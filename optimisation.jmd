```julia
using HDF5, Statistics, Dates
using DynamicGrids, Dispersal, LossFunctions, Unitful, LabelledArrays
using Flatten, FieldMetadata
using DataFrames, CSV, Optim
using Unitful: d
Threads.nthreads()
```




# Override default parameter range limits
```julia
import FieldMetadata: @relimits, limits, @reflattenable, flattenable

@relimits struct HumanDispersal
    human_exponent  | (0.0, 3.0)
    dist_exponent   | (0.0, 3.0)
    dispersalperpop | (0.0, 1e-8)
    max_dispersers  | (1e1, 1e4)
end
# Constant growth
@relimits struct ExactLogisticGrowth
    intrinsicrate | (0.0, 10.0)
end
# Alee
@relimits struct AlleeExtinction
    minfounders | (2e0, 1e3)
end

# Dont parametrise carrycap
@reflattenable struct ExactLogisticGrowthMap
    carrycap | false
end
# Don't parametrise λ, it will just be the top limit: we need to estimate it
@reflattenable struct ExponentialKernel
    λ | false
end
```

Load simualtions for USA

```julia
datafile = "spread_inputs_US_SWD.h5"
starttime = DateTime(2008, 5)
timestep = Month(1)
stoptime = DateTime(2013, 12)
include("setup_rulesets.jl")

# Define combinations for comparison  ##########################
kwargs = (init=init, mask=boolmask, timestep=timestep)

full = Ruleset(humandisp, Chain(localdisp, allee, growth); kwargs...)
nolocal = Ruleset(humandisp, allee, growth; kwargs...);
noallee = Ruleset(humandisp, Chain(localdisp, growth); kwargs...);
nohuman = Ruleset(Chain(localdisp, allee, growth); kwargs...);
noclimate = Ruleset(humandisp, Chain(localdisp, allee, constant_growth); kwargs...)
ruleset = Ruleset(Chain(localdisp, growth); kwargs...);
```

Optimiser settings

```julia
# Define simulation settings
cellsize = 1.0
framesperstep = 12

# Define parametrization objective ########################################
detectionthreshold = 1e7
occurance = convert.(Bool, read(data["state_year_spread"]))
regionlookup = convert.(Int, replace(read(data["x_y_state"]), NaN=>0))[:, :, 1]
steps = size(occurance, 2)
startmonth = 5
objective = RegionObjective(detectionthreshold, regionlookup, occurance, framesperstep, startmonth)
transformfunc = x -> 2x - 1
lossfunc = ZeroOneLoss()
output = RegionOutput(objective; starttime=starttime, stoptime=stoptime, objective=objective)

threading = SingleCoreReplicates()
# threading = Dispersal.ThreadedReplicates()
groupsize = 10
ngroups = 5 # should be physical cpus - 1
iterations = 2

filename = "optimresults_latest.jld2"
rulesetkey = :full
runoptim = true
```

## Run the optimizer

**WARNING** this might take a few days

```julia
if runoptim
    optimresults = @LArray Vector(undef, length(sim_rulesets)) keys(sim_rulesets)
    output.running = false
    simlosses = @LArray [zeros(groupsize * ngroups) for r in 1:length(sim_rulesets)] keys(sim_rulesets)
    for rulesetkey in keys(sim_rulesets)
        println("model: ", rulesetkey)
        ruleset = sim_rulesets[rulesetkey];
        pars = [flatten(ruleset.rules)...]
        ruleset.rules = reconstruct(ruleset.rules, pars .* 0);
        parnames = fieldnameflatten(ruleset.rules, Union{Real,Quantity})
        # Make a labelled array so we can ignore the order
        namedparams = @LArray pars parnames
        show(namedparams)
        parametriser = Parametriser(ruleset, output, objective, transformfunc, lossfunc, ngroups, groupsize, starttime, stoptime, threading);
        # Get the lower and upper limits for params with flatten
        lims = metaflatten(ruleset.rules, FieldMetadata.limits, Union{Real,Quantity})
        lower = [l[1] for l in lims]
        upper = [l[2] for l in lims]
        res = Optim.optimize(parametriser, lower, upper, namedparams, SAMIN(),
                             Optim.Options(iterations=iterations,
                                           show_trace=true,
                                           store_trace=true
                                          ))
        optimresults[rulesetkey] = res
        simlosses[rulesetkey] = reduce(vcat, parametriser.results)
    end
else
    # Otherwise load saved results and update ruleset (for using in outputs)
    @load filename optimresults
end
```


# Build results dataframes

```julia
allparams = Optim.minimizer(optimresults[:full])
paramnames = symbols(allparams)
r = Optim.minimizer(optimresults[:full])
rulesetkeys = keys(sim_rulesets)
paramvectors = LArray{rulesetkeys}([deepcopy(allparams) for r in rulesetkeys]);
paramdf = DataFrame(paramvectors, collect(rulesetkeys))
insert!(paramdf, 1, collect(paramnames), :names)
lims = metaflatten(sim_rulesets[:full].rules, FieldMetadata.limits, Union{Real,Quantity})
lower = [l[1] for l in lims]
upper = [l[2] for l in lims]
insert!(paramdf, 2, lower, :lowerbound)
insert!(paramdf, 3, upper, :upperbound)

# Loss/accuracy results dataframe
sumstats = [:USloss, :USstd, :USaccuracy, :EUloss, :EUstd, :EUaccuracy]
resultdf = DataFrame(map(k -> k=>zeros(length(sumstats)), keys(optimresults))...)
insert!(resultdf, 1, sumstats, :stat)
accuracy(target, loss) = one(loss) - loss/length(target)

output.running = false
# Loss and accuracy for the USA
for rulesetkey in keys(optimresults)
    println(rulesetkey)
    pars = Optim.minimizer(optimresults[rulesetkey])
    println(pars)
    # Set the parameters to zero, to make sure they are updated in the optimizer
    ruleset = sim_rulesets[rulesetkey]
    ruleset.rules = reconstruct(ruleset.rules, pars .* 0)
    # Make a labelled array so we can ignore the order
    for paramkey in symbols(pars)
        paramkey in paramnames || continue
        paramdf[rulesetkey][paramkey] = pars[paramkey]
    end
    # Fill out the loss for the USA
    parametriser = Parametriser(ruleset, output, objective, transformfunc,
                                lossfunc, ngroups, groupsize, starttime, stoptime, threading)
    loss = parametriser(pars)
    resultdf[rulesetkey][findfirst(x->x==:USloss, sumstats)] = loss
    resultdf[rulesetkey][findfirst(x->x==:USstd, sumstats)] = std(vcat(parametriser.results...))
    # Fill out the accuracy for the USA
    resultdf[rulesetkey][findfirst(x->x==:USaccuracy, sumstats)] =
        accuracy(Dispersal.targets(objective), loss)
end
```


# Loss and accuracy for the EU

```julia
include("setup_rulesets.jl")
datafile = "spread_inputs_EU_SWD.h5"
# Update rulset for EU ouputs if you need them
sim_rulesets, init, objective, output = setup_rulesets(datafile, starttime, timestep, stoptime);

for rulesetkey in keys(optimresults)
    println(rulesetkey)
    pars = Optim.minimizer(optimresults[rulesetkey])
    # Set the parameters to zero, to make sure they are updated in the optimizer
    ruleset = sim_rulesets[rulesetkey]
    ruleset.rules = reconstruct(ruleset.rules, pars .* 0) # Fill out the loss for the USA
    parametriser = Parametriser(ruleset, output, objective, transformfunc,
                                lossfunc, ngroups, groupsize, starttime, stoptime, threading)
    loss = parametriser(pars)
    resultdf[rulesetkey][findfirst(x->x==:EUloss, sumstats)] = loss
    resultdf[rulesetkey][findfirst(x->x==:EUstd, sumstats)] = std(vcat(parametriser.results...))
    # Fill out the accuracy for the USA
    resultdf[rulesetkey][findfirst(x->x==:EUaccuracy, sumstats)] =
        accuracy(Dispersal.targets(objective), loss)
end
```
